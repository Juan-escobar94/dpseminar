\documentclass{article}


\begin{document}
\title{Dynamic Programming}
\author{Juan Andr√©s Osorio Escobar}
\date{\today}
\maketitle

\begin{abstract}
Dynamic Programming (short \textbf{\emph{DP}}) refers to a problem solving paradigm,
  which seeks to solve a problem by solving related subproblems and combining their solutions to solve the main problem.
  As these subproblems may be encountered repeatedly along the solving process, DP algorithms store their solution, so 
  that the same computation is never done twice, potentially making the computation for the main solution much faster at 
  the cost of increased memory usage. DP is often applied to solve optimization problems and counting problems.

  In order for a problem to be applicable to optimization it must exhibit the following traits:

  \begin{itemize}
    \item \textbf{Optimal substructures}: The solution for a subproblem is part of the solution of the original problem \cite{halim2013competitive}.
    \item \textbf{Ovelapping subproblems}: When a recursive algorithm repeatedly revisist the same subproblem in different branches along its recursion tree, we say that the problem has overlapping subproblems \cite{cormen2009introduction}. This is the key characteristic
    which allows the search space for a problem to be drastically reduced \cite{halim2013competitive}.
  \end{itemize}
  
  When these DP criteria are met, DP solutions may reduce the run time of a problem from exponential 
  time complexity (using complete search algorithms), to polynomial time complexity. DP algorithms can be implemented
  in one of two ways: either recursively/top-down with memoization, or bottom-up. Both methods make use of a table in which the solution to subproblems are stored.
  We shall revisit also both techniques and analyze their pros and cons.

  
  
\bibliographystyle{acm}
\bibliography{references.bib}
  
\end{abstract}


\end{document}
